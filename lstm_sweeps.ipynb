{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcb694f",
   "metadata": {},
   "source": [
    "# **Sweeps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee2fb9",
   "metadata": {},
   "source": [
    "## **Pre-Sweep**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77742a",
   "metadata": {},
   "source": [
    "### **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4b3256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\tobys\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/tobys/Downloads/GBM-ML-main/GBM-ML-main\")\n",
    "\n",
    "wandb.login(key='601e2bae7faf9f70cd48f1c1ae9ed183b5193d1c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8fbe8",
   "metadata": {},
   "source": [
    "### **Define Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bd1468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "lcs = pd.read_csv('lcs.csv')\n",
    "channels = ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'na', 'nb', 'b0', 'b1']\n",
    "\n",
    "# Fill missing channels with noise\n",
    "for channel in channels: \n",
    "    missing_indices = lcs[channel].isnull()  \n",
    "    num_missing = missing_indices.sum()\n",
    "    noise = np.random.normal(loc=lcs[channel].mean(), scale=lcs[channel].std(), size=num_missing)  \n",
    "    lcs.loc[missing_indices, channel] = noise   \n",
    "\n",
    "time_series_list = []\n",
    "burst_ids = []\n",
    "grouped = lcs.groupby('burst')\n",
    "for burst, group in grouped:\n",
    "    time_series_data = group[channels].values\n",
    "    time_series_tensor = torch.tensor(time_series_data, dtype=torch.float32)\n",
    "    time_series_list.append(time_series_tensor)\n",
    "    burst_ids.append(burst)\n",
    "\n",
    "# Padding with zeros\n",
    "time_series_list = nn.utils.rnn.pad_sequence(time_series_list, batch_first=True, padding_value=0.0)\n",
    "\n",
    "# Set sequence_length for the sweep config and model\n",
    "sequence_length = time_series_list.shape[1]\n",
    "\n",
    "# Normalize the light curves\n",
    "scaler = StandardScaler()\n",
    "time_series_list_2d = time_series_list.reshape(time_series_list.shape[0], -1)\n",
    "time_series_list_2d = scaler.fit_transform(time_series_list_2d)\n",
    "time_series_list = time_series_list_2d.reshape(time_series_list.shape)\n",
    "time_series_list = torch.tensor(time_series_list, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Dataset Class\n",
    "class GRBDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11268f9b",
   "metadata": {},
   "source": [
    "### **Define Model Components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "689d0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM Autoencoder Model w/ attention\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, latent_size, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "        self.fc_latent = nn.Linear(hidden_size * 2, latent_size)  # compress to latent\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # out: [batch, time, hidden_size*2]\n",
    "\n",
    "        attn_scores = self.attention(out)              # [batch, time, 1]\n",
    "        attn_weights = torch.softmax(attn_scores, 1)   # normalize over time\n",
    "        context = torch.sum(attn_weights * out, dim=1) # [batch, hidden_size*2]\n",
    "\n",
    "        latent = self.fc_latent(context)               # [batch, latent_size]\n",
    "        return latent, attn_weights                    # return latent features (what we're trying to extract) + attention weights\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, num_layers, output_size, seq_len):\n",
    "        super().__init__()\n",
    "        self.fc_expand = nn.Linear(latent_size, hidden_size * 2)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_size * 2,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, latent):\n",
    "        # Expand latent vector to all timesteps\n",
    "        repeated = self.fc_expand(latent).unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "        \n",
    "        output, _ = self.lstm(repeated)     # [batch, time, hidden_size*2]\n",
    "        output = self.fc_out(output)        # [batch, time, output_size]\n",
    "        return output\n",
    "\n",
    "\n",
    "class BiLSTMAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, latent_size, seq_len, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size, num_layers, latent_size, dropout)\n",
    "        self.decoder = Decoder(latent_size, hidden_size, num_layers, input_size, seq_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent, attn_weights = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f632f",
   "metadata": {},
   "source": [
    "## **Sweep**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2a2a",
   "metadata": {},
   "source": [
    "### **Sweep Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542d86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_sweep():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    # Get data\n",
    "    dataset = GRBDataset(time_series_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    model = BiLSTMAutoencoder(\n",
    "    config.input_dim,\n",
    "    config.hidden_dim,\n",
    "    config.num_layers,\n",
    "    config.latent_dim,\n",
    "    sequence_length,\n",
    "    config.dropout\n",
    ")\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
    "\n",
    "\n",
    "    # Get data\n",
    "    dataset = GRBDataset(time_series_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(config.num_epochs):\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            batch = batch.float()\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, _ = model(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step(loss)\n",
    "\n",
    "            if i == len(dataloader) - 1:\n",
    "                print(f\"Epoch {epoch+1}, Final batch loss: {loss.item():.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"batch_size\": batch.shape[0],\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "    wandb.log({\"final_loss\": loss.item()})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e06fec",
   "metadata": {},
   "source": [
    "### **Sweep Config** - _THE IMPORTANT PART_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7fbae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sweeps = 15\n",
    "\n",
    "# Flags to toggle which hyperparameters to sweep\n",
    "config_flags = {\n",
    "    'sweep_input_dim': False,\n",
    "    'sweep_hidden_dim': False,\n",
    "    'sweep_latent_dim': False,\n",
    "    'sweep_num_layers': False,\n",
    "    'sweep_batch_size': False,\n",
    "    'sweep_learning_rate': True,\n",
    "    'sweep_dropout': False,\n",
    "    'sweep_method': 'bayes'  # 'random', 'bayes', or 'grid'\n",
    "}\n",
    "\n",
    "# Default values if not swept\n",
    "fixed_defaults = {\n",
    "    'input_dim': 14,\n",
    "    'hidden_dim': 16,\n",
    "    'latent_dim': 64,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.00022,\n",
    "    'dropout': 0.4,\n",
    "    'num_epochs': 15\n",
    "}\n",
    "\n",
    "def generate_sweep_config(flags, defaults):\n",
    "    sweep_config = {\n",
    "        'method': flags['sweep_method'],\n",
    "        'metric': {'name': 'loss', 'goal': 'minimize'},\n",
    "        'parameters': {}\n",
    "    }\n",
    "\n",
    "    sweep_config['parameters']['input_dim'] = {'values': [12, 14, 16]} if flags['sweep_input_dim'] else {'value': defaults['input_dim']}\n",
    "    sweep_config['parameters']['hidden_dim'] = {'values': [16, 32, 64, 128]} if flags['sweep_hidden_dim'] else {'value': defaults['hidden_dim']}\n",
    "    sweep_config['parameters']['latent_dim'] = {'values': [8, 16, 32, 64]} if flags['sweep_latent_dim'] else {'value': defaults['latent_dim']}\n",
    "    sweep_config['parameters']['num_layers'] = {'values': [1, 2, 3]} if flags['sweep_num_layers'] else {'value': defaults['num_layers']}\n",
    "    sweep_config['parameters']['batch_size'] = {'values': [8, 16, 32]} if flags['sweep_batch_size'] else {'value': defaults['batch_size']}\n",
    "\n",
    "    if flags['sweep_learning_rate']:\n",
    "        sweep_config['parameters']['learning_rate'] = {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.00001,\n",
    "            'max': 0.001\n",
    "        }\n",
    "    else:\n",
    "        sweep_config['parameters']['learning_rate'] = {'value': defaults['learning_rate']}\n",
    "\n",
    "    sweep_config['parameters']['dropout'] = {'values': [0.0, 0.2, 0.3, 0.4]} if flags['sweep_dropout'] else {'value': defaults['dropout']}\n",
    "\n",
    "    sweep_config['parameters']['num_epochs'] = {'value': defaults['num_epochs']}\n",
    "\n",
    "    return sweep_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806476b2",
   "metadata": {},
   "source": [
    "### **Run Sweep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b38992e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bwaeu41p\n",
      "Sweep URL: https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/sweeps/bwaeu41p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 90rfxpqp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_dim: 14\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002991127364880311\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\OneDrive\\Desktop\\GBM-ML-LSTM\\wandb\\run-20250806_130028-90rfxpqp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/runs/90rfxpqp' target=\"_blank\">kind-sweep-1</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/sweeps/bwaeu41p' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/sweeps/bwaeu41p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/sweeps/bwaeu41p' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/sweeps/bwaeu41p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/runs/90rfxpqp' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/runs/90rfxpqp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-1</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/runs/90rfxpqp' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep/runs/90rfxpqp</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-LR-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250806_130028-90rfxpqp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 90rfxpqp errored:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Traceback (most recent call last):\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"c:\\Users\\tobys\\anaconda3\\envs\\star-pinn\\lib\\site-packages\\wandb\\agents\\pyagent.py\", line 302, in _run_job\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     self._function()\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m   File \"C:\\Users\\tobys\\AppData\\Local\\Temp\\ipykernel_3484\\1609760947.py\", line 42, in train_lstm_sweep\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m     if batch == len(dataloader) - 1:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m RuntimeError: Boolean value of Tensor with more than one value is ambiguous\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sweep_config = generate_sweep_config(config_flags, fixed_defaults)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"GBM-LSTM-LR-Sweep\")\n",
    "wandb.agent(sweep_id, function=train_lstm_sweep, count=num_sweeps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star-pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
