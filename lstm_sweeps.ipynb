{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcb694f",
   "metadata": {},
   "source": [
    "# **Sweeps**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee2fb9",
   "metadata": {},
   "source": [
    "## **Pre-Sweep**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d77742a",
   "metadata": {},
   "source": [
    "### **Import Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"C:/Users/tobys/Downloads/GBM-ML-main/GBM-ML-main\")\n",
    "\n",
    "wandb.login(key='601e2bae7faf9f70cd48f1c1ae9ed183b5193d1c')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8fbe8",
   "metadata": {},
   "source": [
    "### **Define Dataset Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bd1468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "lcs = pd.read_csv('lcs.csv')\n",
    "channels = ['n0', 'n1', 'n2', 'n3', 'n4', 'n5', 'n6', 'n7', 'n8', 'n9', 'na', 'nb', 'b0', 'b1']\n",
    "\n",
    "# Fill missing channels with noise\n",
    "for channel in channels: \n",
    "    missing_indices = lcs[channel].isnull()  \n",
    "    num_missing = missing_indices.sum()\n",
    "    noise = np.random.normal(loc=lcs[channel].mean(), scale=lcs[channel].std(), size=num_missing)  \n",
    "    lcs.loc[missing_indices, channel] = noise   \n",
    "\n",
    "time_series_list = []\n",
    "burst_ids = []\n",
    "grouped = lcs.groupby('burst')\n",
    "for burst, group in grouped:\n",
    "    time_series_data = group[channels].values\n",
    "    time_series_tensor = torch.tensor(time_series_data, dtype=torch.float32)\n",
    "    time_series_list.append(time_series_tensor)\n",
    "    burst_ids.append(burst)\n",
    "\n",
    "# Padding with zeros\n",
    "time_series_list = nn.utils.rnn.pad_sequence(time_series_list, batch_first=True, padding_value=0.0)\n",
    "\n",
    "# Set sequence_length for the sweep config and model\n",
    "sequence_length = time_series_list.shape[1]\n",
    "\n",
    "# Normalize the light curves\n",
    "scaler = StandardScaler()\n",
    "time_series_list_2d = time_series_list.reshape(time_series_list.shape[0], -1)\n",
    "time_series_list_2d = scaler.fit_transform(time_series_list_2d)\n",
    "time_series_list = time_series_list_2d.reshape(time_series_list.shape)\n",
    "time_series_list = torch.tensor(time_series_list, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Dataset Class\n",
    "class GRBDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11268f9b",
   "metadata": {},
   "source": [
    "### **Define Model Components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "689d0c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bidirectional LSTM Autoencoder Model w/ attention\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, latent_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "        self.fc_latent = nn.Linear(hidden_size * 2, latent_size)  # compress to latent\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # out: [batch, time, hidden_size*2]\n",
    "\n",
    "        attn_scores = self.attention(out)              # [batch, time, 1]\n",
    "        attn_weights = torch.softmax(attn_scores, 1)   # normalize over time\n",
    "        context = torch.sum(attn_weights * out, dim=1) # [batch, hidden_size*2]\n",
    "\n",
    "        latent = self.fc_latent(context)               # [batch, latent_size]\n",
    "        return latent, attn_weights\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, num_layers, output_size, seq_len):\n",
    "        super().__init__()\n",
    "        self.fc_expand = nn.Linear(latent_size, hidden_size * 2)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=hidden_size * 2,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.fc_out = nn.Linear(hidden_size * 2, output_size)\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def forward(self, latent):\n",
    "        # Expand latent vector to all timesteps\n",
    "        repeated = self.fc_expand(latent).unsqueeze(1).repeat(1, self.seq_len, 1)\n",
    "        \n",
    "        out, _ = self.lstm(repeated)  # [batch, time, hidden_size*2]\n",
    "        out = self.fc_out(out)        # [batch, time, output_size]\n",
    "        return out\n",
    "\n",
    "\n",
    "class BiLSTM_Autoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, latent_size, seq_len):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size, hidden_size, num_layers, latent_size)\n",
    "        self.decoder = Decoder(latent_size, hidden_size, num_layers, input_size, seq_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent, attn_weights = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54f632f",
   "metadata": {},
   "source": [
    "## **Sweep**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bb2a2a",
   "metadata": {},
   "source": [
    "### **Sweep Training Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "542d86ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm_sweep():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    # Get data\n",
    "    dataset = GRBDataset(time_series_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    model = BiLSTM_Autoencoder(\n",
    "    config.input_dim,\n",
    "    config.hidden_dim,\n",
    "    config.num_layers,\n",
    "    config.latent_dim,\n",
    "    sequence_length\n",
    ")\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n",
    "    # Get data\n",
    "    dataset = GRBDataset(time_series_list)\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(config.num_epochs):\n",
    "        total_loss = 0\n",
    "        for batch in dataloader:\n",
    "            batch = batch.float()\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, _, _ = model(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
    "\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"loss\": loss.item(),\n",
    "            \"batch_size\": batch.shape[0],\n",
    "            \"learning_rate\": optimizer.param_groups[0]['lr']\n",
    "        })\n",
    "\n",
    "    wandb.log({\"final_loss\": loss.item()})\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e06fec",
   "metadata": {},
   "source": [
    "### **Sweep Config** - _THE IMPORTANT PART_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7fbae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sweeps = 50\n",
    "\n",
    "# Flags to toggle which hyperparameters to sweep\n",
    "config_flags = {\n",
    "    'sweep_input_dim': False,\n",
    "    'sweep_hidden_dim': True,\n",
    "    'sweep_latent_dim': True,\n",
    "    'sweep_num_layers': True,\n",
    "    'sweep_batch_size': False,\n",
    "    'sweep_learning_rate': False,\n",
    "    'sweep_dropout': True,\n",
    "    'sweep_method': 'random'  # 'random', 'bayes', or 'grid'\n",
    "}\n",
    "\n",
    "# Default values if not swept\n",
    "fixed_defaults = {\n",
    "    'input_dim': 14,\n",
    "    'hidden_dim': 64,\n",
    "    'latent_dim': 32,\n",
    "    'num_layers': 2,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.00022,\n",
    "    'dropout': 0.2,\n",
    "    'num_epochs': 15\n",
    "}\n",
    "\n",
    "def generate_sweep_config(flags, defaults):\n",
    "    sweep_config = {\n",
    "        'method': flags['sweep_method'],\n",
    "        'metric': {'name': 'loss', 'goal': 'minimize'},\n",
    "        'parameters': {}\n",
    "    }\n",
    "\n",
    "    sweep_config['parameters']['input_dim'] = {'values': [12, 14, 16]} if flags['sweep_input_dim'] else {'value': defaults['input_dim']}\n",
    "    sweep_config['parameters']['hidden_dim'] = {'values': [16, 32, 64, 128]} if flags['sweep_hidden_dim'] else {'value': defaults['hidden_dim']}\n",
    "    sweep_config['parameters']['latent_dim'] = {'values': [8, 16, 32, 64]} if flags['sweep_latent_dim'] else {'value': defaults['latent_dim']}\n",
    "    sweep_config['parameters']['num_layers'] = {'values': [1, 2, 3]} if flags['sweep_num_layers'] else {'value': defaults['num_layers']}\n",
    "    sweep_config['parameters']['batch_size'] = {'values': [8, 16, 32]} if flags['sweep_batch_size'] else {'value': defaults['batch_size']}\n",
    "\n",
    "    if flags['sweep_learning_rate']:\n",
    "        sweep_config['parameters']['learning_rate'] = {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 0.0001,\n",
    "            'max': 0.01\n",
    "        }\n",
    "    else:\n",
    "        sweep_config['parameters']['learning_rate'] = {'value': defaults['learning_rate']}\n",
    "\n",
    "    sweep_config['parameters']['dropout'] = {'values': [0.0, 0.2, 0.3, 0.4]} if flags['sweep_dropout'] else {'value': defaults['dropout']}\n",
    "\n",
    "    sweep_config['parameters']['num_epochs'] = {'value': defaults['num_epochs']}\n",
    "\n",
    "    return sweep_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806476b2",
   "metadata": {},
   "source": [
    "### **Run Sweep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b38992e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: r5f0vkhq\n",
      "Sweep URL: https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: abmxay26 with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0.3\n",
      "wandb: \thidden_dim: 16\n",
      "wandb: \tinput_dim: 14\n",
      "wandb: \tlatent_dim: 16\n",
      "wandb: \tlearning_rate: 0.00022\n",
      "wandb: \tnum_epochs: 15\n",
      "wandb: \tnum_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Downloads\\GBM-ML-main\\GBM-ML-main\\wandb\\run-20250802_112126-abmxay26</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/abmxay26' target=\"_blank\">fresh-sweep-1</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/abmxay26' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/abmxay26</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9985\n",
      "Epoch 2, Loss: 0.9841\n",
      "Epoch 3, Loss: 1.0109\n",
      "Epoch 4, Loss: 0.9606\n",
      "Epoch 5, Loss: 0.9428\n",
      "Epoch 6, Loss: 0.9283\n",
      "Epoch 7, Loss: 0.9154\n",
      "Epoch 8, Loss: 0.9045\n",
      "Epoch 9, Loss: 0.8958\n",
      "Epoch 10, Loss: 0.8884\n",
      "Epoch 11, Loss: 0.8830\n",
      "Epoch 12, Loss: 0.8786\n",
      "Epoch 13, Loss: 0.8727\n",
      "Epoch 14, Loss: 0.8687\n",
      "Epoch 15, Loss: 0.8649\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>final_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▁█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>2</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_loss</td><td>0.24123</td></tr><tr><td>learning_rate</td><td>0.00022</td></tr><tr><td>loss</td><td>0.24123</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fresh-sweep-1</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/abmxay26' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/abmxay26</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250802_112126-abmxay26\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 24zs98os with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0\n",
      "wandb: \thidden_dim: 32\n",
      "wandb: \tinput_dim: 14\n",
      "wandb: \tlatent_dim: 64\n",
      "wandb: \tlearning_rate: 0.00022\n",
      "wandb: \tnum_epochs: 15\n",
      "wandb: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Downloads\\GBM-ML-main\\GBM-ML-main\\wandb\\run-20250802_112700-24zs98os</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/24zs98os' target=\"_blank\">kind-sweep-2</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/24zs98os' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/24zs98os</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9963\n",
      "Epoch 2, Loss: 0.9697\n",
      "Epoch 3, Loss: 0.9353\n",
      "Epoch 4, Loss: 0.9097\n",
      "Epoch 5, Loss: 0.8931\n",
      "Epoch 6, Loss: 0.8873\n",
      "Epoch 7, Loss: 0.8797\n",
      "Epoch 8, Loss: 0.8686\n",
      "Epoch 9, Loss: 0.8603\n",
      "Epoch 10, Loss: 0.8538\n",
      "Epoch 11, Loss: 0.8485\n",
      "Epoch 12, Loss: 0.8430\n",
      "Epoch 13, Loss: 0.8415\n",
      "Epoch 14, Loss: 0.8511\n",
      "Epoch 15, Loss: 0.8370\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>final_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>█▃▁▂▂▃▃▅▂▁▃▄▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>2</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_loss</td><td>0.24377</td></tr><tr><td>learning_rate</td><td>0.00022</td></tr><tr><td>loss</td><td>0.24377</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-sweep-2</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/24zs98os' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/24zs98os</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250802_112700-24zs98os\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: zwu2uas0 with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0.2\n",
      "wandb: \thidden_dim: 32\n",
      "wandb: \tinput_dim: 14\n",
      "wandb: \tlatent_dim: 16\n",
      "wandb: \tlearning_rate: 0.00022\n",
      "wandb: \tnum_epochs: 15\n",
      "wandb: \tnum_layers: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Downloads\\GBM-ML-main\\GBM-ML-main\\wandb\\run-20250802_173806-zwu2uas0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/zwu2uas0' target=\"_blank\">blooming-sweep-3</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/zwu2uas0' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/zwu2uas0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9902\n",
      "Epoch 2, Loss: 0.9700\n",
      "Epoch 3, Loss: 0.9375\n",
      "Epoch 4, Loss: 0.9113\n",
      "Epoch 5, Loss: 0.8962\n",
      "Epoch 6, Loss: 0.8860\n",
      "Epoch 7, Loss: 0.8774\n",
      "Epoch 8, Loss: 0.8678\n",
      "Epoch 9, Loss: 0.8595\n",
      "Epoch 10, Loss: 0.8531\n",
      "Epoch 11, Loss: 0.8481\n",
      "Epoch 12, Loss: 0.8423\n",
      "Epoch 13, Loss: 0.8408\n",
      "Epoch 14, Loss: 0.8566\n",
      "Epoch 15, Loss: 0.8328\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>final_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▃▄▂▁▄█▄▄▁▃▆▂▂▆▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>2</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_loss</td><td>0.25396</td></tr><tr><td>learning_rate</td><td>0.00022</td></tr><tr><td>loss</td><td>0.25396</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">blooming-sweep-3</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/zwu2uas0' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/zwu2uas0</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250802_173806-zwu2uas0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: 04y6xkv4 with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0.4\n",
      "wandb: \thidden_dim: 128\n",
      "wandb: \tinput_dim: 14\n",
      "wandb: \tlatent_dim: 16\n",
      "wandb: \tlearning_rate: 0.00022\n",
      "wandb: \tnum_epochs: 15\n",
      "wandb: \tnum_layers: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Downloads\\GBM-ML-main\\GBM-ML-main\\wandb\\run-20250802_174658-04y6xkv4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/04y6xkv4' target=\"_blank\">floral-sweep-4</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/04y6xkv4' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/04y6xkv4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tobys\\anaconda3\\envs\\star-pinn\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9053\n",
      "Epoch 2, Loss: 0.8634\n",
      "Epoch 3, Loss: 0.8493\n",
      "Epoch 4, Loss: 0.8405\n",
      "Epoch 5, Loss: 0.8335\n",
      "Epoch 6, Loss: 0.8296\n",
      "Epoch 7, Loss: 0.8124\n",
      "Epoch 8, Loss: 0.8093\n",
      "Epoch 9, Loss: 0.8030\n",
      "Epoch 10, Loss: 0.8056\n",
      "Epoch 11, Loss: 0.8013\n",
      "Epoch 12, Loss: 0.7952\n",
      "Epoch 13, Loss: 0.8019\n",
      "Epoch 14, Loss: 0.7901\n",
      "Epoch 15, Loss: 0.8031\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>final_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▃▇▃▆▄▅▄▆▅█▄▄▁▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>2</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_loss</td><td>0.1873</td></tr><tr><td>learning_rate</td><td>0.00022</td></tr><tr><td>loss</td><td>0.1873</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">floral-sweep-4</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/04y6xkv4' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/04y6xkv4</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250802_174658-04y6xkv4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Sweep Agent: Waiting for job.\n",
      "wandb: Job received.\n",
      "wandb: Agent Starting Run: wxwebaup with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0.3\n",
      "wandb: \thidden_dim: 16\n",
      "wandb: \tinput_dim: 14\n",
      "wandb: \tlatent_dim: 64\n",
      "wandb: \tlearning_rate: 0.00022\n",
      "wandb: \tnum_epochs: 15\n",
      "wandb: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Downloads\\GBM-ML-main\\GBM-ML-main\\wandb\\run-20250802_180700-wxwebaup</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/wxwebaup' target=\"_blank\">olive-sweep-5</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/wxwebaup' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/wxwebaup</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0011\n",
      "Epoch 2, Loss: 0.9895\n",
      "Epoch 3, Loss: 0.9750\n",
      "Epoch 4, Loss: 0.9583\n",
      "Epoch 5, Loss: 0.9409\n",
      "Epoch 6, Loss: 0.9268\n",
      "Epoch 7, Loss: 0.9160\n",
      "Epoch 8, Loss: 0.9069\n",
      "Epoch 9, Loss: 0.8999\n",
      "Epoch 10, Loss: 0.8974\n",
      "Epoch 11, Loss: 0.8925\n",
      "Epoch 12, Loss: 0.8871\n",
      "Epoch 13, Loss: 0.8824\n",
      "Epoch 14, Loss: 0.8795\n",
      "Epoch 15, Loss: 0.8742\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>final_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▄▂▂▇▄▅▇▁▄▅▅█▆█▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>2</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_loss</td><td>0.21622</td></tr><tr><td>learning_rate</td><td>0.00022</td></tr><tr><td>loss</td><td>0.21622</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">olive-sweep-5</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/wxwebaup' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/wxwebaup</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250802_180700-wxwebaup\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: gccoawxu with config:\n",
      "wandb: \tbatch_size: 16\n",
      "wandb: \tdropout: 0.3\n",
      "wandb: \thidden_dim: 128\n",
      "wandb: \tinput_dim: 14\n",
      "wandb: \tlatent_dim: 16\n",
      "wandb: \tlearning_rate: 0.00022\n",
      "wandb: \tnum_epochs: 15\n",
      "wandb: \tnum_layers: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\tobys\\Downloads\\GBM-ML-main\\GBM-ML-main\\wandb\\run-20250802_181715-gccoawxu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/gccoawxu' target=\"_blank\">quiet-sweep-6</a></strong> to <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/sweeps/r5f0vkhq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/gccoawxu' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/gccoawxu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9523\n",
      "Epoch 2, Loss: 0.8907\n",
      "Epoch 3, Loss: 0.8682\n",
      "Epoch 4, Loss: 0.8970\n",
      "Epoch 5, Loss: 0.9223\n",
      "Epoch 6, Loss: 0.8422\n",
      "Epoch 7, Loss: 0.8226\n",
      "Epoch 8, Loss: 0.8158\n",
      "Epoch 9, Loss: 0.8339\n",
      "Epoch 10, Loss: 0.9254\n",
      "Epoch 11, Loss: 0.7943\n",
      "Epoch 12, Loss: 0.7873\n",
      "Epoch 13, Loss: 0.7834\n",
      "Epoch 14, Loss: 0.7948\n",
      "Epoch 15, Loss: 0.8067\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>final_loss</td><td>▁</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁▁█▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch_size</td><td>2</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>final_loss</td><td>0.24448</td></tr><tr><td>learning_rate</td><td>0.00022</td></tr><tr><td>loss</td><td>0.24448</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-sweep-6</strong> at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/gccoawxu' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep/runs/gccoawxu</a><br> View project at: <a href='https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep' target=\"_blank\">https://wandb.ai/tobiassafie-drexel-university/GBM-LSTM-Sweep</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250802_181715-gccoawxu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sweep_config = generate_sweep_config(config_flags, fixed_defaults)\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"GBM-LSTM-Sweep\")\n",
    "wandb.agent(sweep_id, function=train_lstm_sweep, count=num_sweeps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "star-pinn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
